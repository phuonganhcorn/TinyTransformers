## Transformer from scratch
---
### Overview

The objective of this project is to develop a simplified version of the Transformer model _inspired by the infamous paper "Attention is All You Need."_ Unlike the full-scale Transformer model available in PyTorch, this implementation aims to create a smaller variant. This model has been enhanced by incorporating techniques from Mistral - a state-of-the-art model - to strike a balance between complexity and efficiency.






---
